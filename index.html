<!DOCTYPE html>  
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="InFusion: Inject and Attention Fusion for Multi Concept Zero-Shot Text-based Video Editing"/>
  <meta property="og:description" content="InFusion: Inject and Attention Fusion for Multi Concept Zero Shot Text based Video Editing"/>
  <meta property="og:url" content="https://infusion-zero-edit.github.io/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/iccv_edit.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>InFusion</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/comic-mono@0.0.1/index.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
	    tex2jax: {
	        inlineMath: [['$','$'], ['\\(','\\)']],
	        processEscapes: true
	    }
	});
    </script>

  <script src="static/js/index.js"></script>
  
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="xtitle is-1 publication-title">
              <span style="font-weight: 600;color: #eb002a">Infusion:</span>
              <span>In</span>ject and Attention
              <span>Fusion</span> for Multi Concept Zero-Shot Text-based Video Editing
          </br>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=_D16NbcAAAAJ&hl=en&authuser=1" target="_blank">Anant Khandelwal</a></span>
                  </div>
              </br>
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                	Glance AI &nbsp;&nbsp;&nbsp;
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      
                       <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2308.00135" target="_blank"
                    class="external-link ">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
			    
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Image carousel -->
<section class="hero">
<p class="trdl">TL;DR: Editing<sup>1</sup> your video via pretrained Stable Diffusion<sup>2</sup> model without training.</p>
  <div class="hero-body">
    <div class="container">
              <div class="marquee-item">
                <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" autoplay muted loop playsinline height="100%">
                  <!-- Your video file here -->
                  <source src="static/videos/inp_out_snow.mp4"
                  type="video/mp4">
                sorry, your browser does not support HTML5 Videos.
                </video>
                <p class="text-white"> <c> +Porsche Car, +snowy winter </c> </p>
              </div>
              <div class="marquee-item">
                <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" autoplay muted loop playsinline height="100%">
                  <source src="static/videos/inp_out_autumn.mp4"
                    type="video/mp4">
                  sorry, your browser does not support HTML5 Videos.  
                  </video>
                <p class="text-white"> <c> +Porsche Car, +landmark of autumn </c> </p>
              </div>
              <div class="marquee-item">
                <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" autoplay muted loop playsinline height="100%">
                <source src="static/videos/inp_out_swan.mp4"
                  type="video/mp4">
                sorry, your browser does not support HTML5 Videos.
                </video>
                <p class="text-white"> <c> +Terosaur </c> </p>
              </div>      
              <div class="marquee-item">
                <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" autoplay muted loop playsinline height="100%">
                  <source src="static/videos/inp_out_snowball.mp4"
                    type="video/mp4">
                  sorry, your browser does not support HTML5 Videos.
                  </video>
                <p class="text-white"> <c>+Cherry Blossom</c> </p>
              </div>
              <div class="marquee-item">
                <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" autoplay muted loop playsinline height="100%">
                  <source src="static/videos/inp_out_poppy.mp4"
                    type="video/mp4">
                  sorry, your browser does not support HTML5 Videos.
                  </video>
                <p class="text-white"> <c>+white poppy flowers</c> </p>
              </div>
              <div class="marquee-item">
                <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" autoplay muted loop playsinline height="100%">
                  <source src="static/videos/inp_out_sunset.mp4"
                    type="video/mp4">
                  sorry, your browser does not support HTML5 Videos.
                  </video>
                <p class="text-white"> <c>+sunset</c> </p>
              </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
	  Large text-to-image diffusion models have achieved remarkable success in generating diverse, high-quality images. 
          Additionally, these models have been successfully leveraged to edit input images by just changing the text prompt. 
	  But when these models are applied to videos, the main challenge is to ensure temporal consistency and coherence across frames. 
	  In this paper, we propose <i style="color: #eb002a">InFusion</i>,, a framework for zero-shot text-based video editing leveraging 
	  large pre-trained image diffusion models. Our framework specifically supports editing of multiple concepts with pixel-level 
	  control over diverse concepts mentioned in the editing prompt. Specifically, we inject the difference in features obtained 
	  with source and edit prompts from U-Net residual blocks of decoder layers. When these are combined with injected attention 
	  features, it becomes feasible to query the source contents and scale edited concepts along with the injection of unedited parts. 
	  The editing is further controlled in a fine-grained manner with mask extraction and attention fusion, which cut the edited part 
	  from the source and paste it into the denoising pipeline for the editing prompt. Our framework is a low-cost alternative to one-shot 
	  tuned models for editing since it does not require training. We demonstrated complex concept editing with a generalised image model 
	  (Stable Diffusion v1.5) using LoRA. Adaptation is compatible with all the existing image diffusion techniques. Extensive experimental 
	  results demonstrate the effectiveness of existing methods in rendering high-quality and temporally consistent videos.            
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-2">Pipeline</h2>
        <div class="content has-text-justified">
          <img src="static/images/iccv_edit.png" />
        </div>
        <p class="content has-text-justified">
         <b>InFusion</b>: Leveraging a pre-trained text-to-image model for video editing ensures temporal consistency and editing accuracy with Inject and Attention Fusion.
         The denoising pipeline for source prompt Ps generates the decoder latent from U-Net and attention features from source video, 
		which are injected into the denoising pipeline (initialised with inverted source latent z_T) for edit prompt Pe. 
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Image carousel -->
<section class="section hero is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Additional Results: Video Editing Using Stable Diffusion</h2>
      <div class="marquee-item">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/inp_out_frog.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
        <p class="text-white"><c> + GrassHopper - Frog </c> </p>
      </div>
      <div class="marquee-item">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/inp_out_skyscrapers.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
        <p class="text-white"> <c> +Night View, -Morning View </c> </p>
      </div>
      <div class="marquee-item">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/inp_out_ukiyo.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
        <p class="text-white"> <c> + Ukiyo-e Style</c> </p>
      </div>
      <div class="marquee-item">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1"  class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/inp_out_santa.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
        <p class="text-white"> <c> + santa - Moose </c> </p>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{khandelwal2023infusion,
  title={InFusion: Inject and Attention Fusion for Multi Concept Zero Shot Text based Video Editing},
  author={Khandelwal, Anant},
  journal={arXiv preprint arXiv:2308.00135},
  year={2023}
}
  </code></pre>
    </div>
</section>
<!--End BibTex citation -->


<section class="section">
  <div class="hero-body">
    <div class="container is-max-desktop content">
    <h2 class="title">Explanation</h2>
    <small>1. For better visualization, we only show the edited word in this page. </small> <br/>
    <small>2. All results are directly edited from <a href="https://huggingface.co/runwayml/stable-diffusion-v1-5">Stable diffusion v1.5</a>. We dont use any pretrained video diffusion model. </small> <br/>
    <small>3. Our method does not require any training of Stable diffusion v1.5. </small>
    </div>
  </section>

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/vinthony/project-page-template">modification version</a> of <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> from <a href="https://github.com/vinthony">vinthony</a>.
            You are free to borrow this website. We just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
